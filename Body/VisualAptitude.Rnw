\Sexpr{set_parent('../thesis.Rnw')}
\graphicspath{{Figure/VisualAptitude/}{../Figure/VisualAptitude/}{Images/VisualAptitude/}{../Images/VisualAptitude/}}
\renewcommand{\floatpagefraction}{.99}

\makesavenoteenv{tabular}
<<VisualAptitude-setup, fig.keep='all', cache=FALSE, echo=FALSE, eval=TRUE, include=F>>=
rm(list=ls())
wd <- getwd()

library(reshape2)
suppressMessages(library(ggplot2))
library(plyr)
library(grid)
suppressMessages(library(gridExtra))
library(xtable)
library(stringr)
library(magrittr)
library(extrafont)
library(knitr)

if("Body" %in% list.files()){
  opts_chunk$set(fig.path='Figure/VisualAptitude/fig-', cache.path='cache/', fig.align='center', fig.width=5, fig.height=5, fig.show='hold', par=TRUE, cache=TRUE, concordance=TRUE, autodep=TRUE, dev="CairoPDF")
  datadir <- "./Data/VisualAptitude/"
  imgdir <- "./Figure/VisualAptitude/"
  codedir <- "./Code/VisualAptitude/"
} else {
  opts_chunk$set(fig.path='../Figure/VisualAptitude/fig-', cache.path='cache/', fig.align='center', fig.width=5, fig.height=5, fig.show='hold', par=TRUE, cache=TRUE, concordance=TRUE, autodep=TRUE, root.dir="../", dev="CairoPDF")
  datadir <- "../Data/VisualAptitude/"
  imgdir <- "../Figure/VisualAptitude/"
  codedir <- "../Code/VisualAptitude/"
}
options(replace.assign=TRUE,width=70,scipen=3)

source(paste(codedir, "Analysis.R", sep=""))

sanitize <- function(x){
  str_replace(gsub("_", ".", x, fixed=T), "Pr\\((.{1,}))", "Pr$(\\1)$")
}
@


\chapter{SPATIAL REASONING AND DATA DISPLAYS}\label{VisualAptitude}\label{visualreasoning}

\section{Introduction}
Data displays provide quick summaries of data, models, and results, but not all displays are equally good, nor is any data display equally useful to all viewers. 
Graphics utilize higher-bandwidth visual pathways to encode information~\citep{baddeley1974working}, allowing viewers to quickly and intuitively relate multiple dimensions of numerical quantities.
Well-designed graphics emphasize and present important features of the data while minimizing  features of lesser importance, guiding the viewer towards conclusions that are meaningful in context and supported by the data while maximizing the information encoded in working memory. Under this framework, well-designed graphics reduce memory load and make more cognitive resources available for other tasks (such as drawing conclusions from the data), at the cost of depending on certain visuospatial reasoning abilities. 

Many theories of graphical learning center around the difference between visual and verbal processing: the dual-coding theory emphasizes the utility of complementary information in both domains, while the visual argument hypothesis emphasizes that graphics are more efficient tools for providing data with spatial, temporal, or other implicit ordering, because the spatial dimension can be represented graphically in a more natural manner~\citep{vekiri2002value}. Both of these theories suggest spatial ability impacts a viewer's use of graphics, because spatial ability either influences cognitive resource allocation or affects the processing of spatial relationships between graphical elements. In addition, previous investigations into graphical learning and spatial ability have found relationships between spatial ability and the ability to read information from graphs~\citep{lowrie2007solving}. 
However,  mathematical ability, not spatial ability, was shown~\citep{shah1995conceptual} to be associated with accuracy on a simple two-dimensional line graph. 
Spatial ability becomes more important when more complicated graphical displays are used in comparison tasks: the lower performance of individuals with low spatial ability on tests utilizing diagrams and graphs is attributed ~\citep{mayer1994whom} to the fact that more cognitive resources are required to process the visual stimuli, which leaves fewer resources to make connections and draw conclusions from those stimuli. It is theorized that graphics are a form of ``external cognition"~\citep{scaife1996external} that guide, constrain, and facilitate cognitive behavior~\citep{zhang1997nature}. 

``Lineups" have recently been introduced \citep{buja2009statistical, wickham2010graphical, majumder2013validation} as a tool to evaluate the statistical significance of a graphical finding. Lineups are also useful in assessing the effectiveness of different graphical displays \citep{hofmann2012graphical, loy:2015}. Like their police counterpart, lineups consist of several distractor plots (of randomly generated data) and one target (the data plot). 

\begin{figure}[htp]
\centering
\includegraphics[width=.5\linewidth]{lineup}
\caption[Sample Lineup]{Sample lineup of boxplots. Participants are instructed to choose the plot which appears most different from the others. In this lineup, plot 4 is the target plot, because the two groups have a large difference in medians.\label{fig:lineup}}
\end{figure}

Figure~\ref{fig:lineup} shows a sample lineup of boxplots; participants are expected to identify the most different among the plots shown. In this example, sub-plot 4 is the target  because of the noticeably different locations of the two boxplot medians.


%This method is described in more detail in the next section; here we motivate the importance of understanding the connection between lineups and spatial reasoning. 


Lineups provide a quantitative measurement of the effectiveness of a particular plot: if participants consistently identify the target plot rather than the randomly-generated distractors, the plot effectively shows the difference between real data and random noise. 
This removes much of the subjectivity from user evaluations of display effectiveness, and the procedure is simple enough that it does not generally require participants to be very familiar with data-based graphics. 
While previous research~\citep{lowrie2007solving,mayer1994whom} has examined the link between certain types of graphical perception and spatial skills, it is important to identify any additional visual skills participants utilize to complete the lineup task, as well as better understand demographic characteristics (math education, research experience, age, gender) which may impact performance \citep{humanfactorslineups}. 

In this paper, we present the results of a study designed to compare lineup performance with visual aptitude and reasoning tests, examining the skills necessary to successfully evaluate lineups. 
We compare lineup performace to the visual search task (VST), paper folding test, card rotation test, and figure classification test. 
The VST measures visual search speed\citep{goldstein1973validity}, the paper folding and card rotation tests measures spatial manipulation ability, and the figure classification test measures inductive reasoning\citep{ekstrom1976manual}; 
all of these skills are at least peripherally recruited during the lineup task, but some may dominate in predicting performance on the lineup task. 
We hope to facilitate comparison of the lineup task to known cognitive tests, inform the design of future studies, and better understand the perception of statistical lineups. 


In section \ref{sec:methods} we introduce the tests used in the study and describe how the tests are scored. In section \ref{sec:results} we discuss the study results and compare them with scores previously established test, that also take  demographic characteristics associated with test scores into account. We discuss multi-collinearity in the study results, and use principal components analysis and linear models to draw some conclusions about the similarity between lineups and aptitude tests. Finally, in section \ref{sec:discussion}, we discuss the implications of the study results for the lineup protocol and  possible extensions. 
\section{Methods}\label{sec:methods}

\subsection{The Lineup Protocol}
The lineup protocol~\citep{hofmann2012graphical,wickham2010graphical, buja2009statistical} is a testing framework that allows researchers to quantify the statistical significance of a graphical finding with the same mathematical rigor as conventional hypothesis tests.

In a lineup test, the plot of the data is placed randomly among a set of, generally 19, distractor plots (or {\it null plots}) that are rendered from data generated by a model, without a signal (a null model). This sheet of charts is then shown to human observers, who are asked to identify the display that is ``the most different". If an observer identifies the plot drawn from the actual data, this can be reasonably taken as evidence that the data it shows is different from the data of other plots.
Let $X$ be the number of observers (out of $n$) who identify the data plot from the lineup. Under the null hypothesis that the data plot is not different from the other plots, $X$ has approximately a Binomial distribution \citep{wickham2010graphical, majumder2013validation}. If $k$ of the observers identify the data plot from the lineup, the probability $P(X \ge k)$ is the $p$-value of the corresponding visual test. 
%
By aggregating responses from different individuals the lineup protocol therefore allows an objective evaluation of a graphical finding. 

Additionally, however, we can aggregate the scores from the same individual on several lineups to objectively assess an individual's performance on the lineup task. 

For this approach, we derive a score for an individual as follows:

Assume that an observer has evaluated $K$ lineups of size $m$ (consisting of $m-1$ decoy plots and 1 target), and successfully identified the target in $n_c$ of these plots, while missing the target in $n_w$ of them. 
The score for this individual is then given as:
\begin{eqnarray}\label{eq.scoring1}
n_c - n_w/(m-1).
\end{eqnarray}
Note that the sum of answers, $n_c + n_w$, is at most $K$, but may be less, if an observer chooses to not answer one of the lineup tasks or runs out of time.

The scoring scheme as given in (\ref{eq.scoring1}) is chosen so that if participants are guessing, the expected score is 0. 

Statistical lineups depend on the ability to search for a signal amid a set of distractors (visual search) and the ability to infer patterns from stimuli (pattern recognition). Depending on the choice of plot shown in the lineup, the task of identifying the most different plot might require additional abilities from   participants, e.g.~ polar coordinates depend on the ability to mentally rotate stimuli (spatial rotation) and mentally manipulate graphs (spatial rotation and manipulation). By breaking the lineup task down into its components, we  determine which visuospatial factors most strongly correlate with lineup performance, using carefully chosen cognitive tests to assess these aspects of visuospatial ability. 

Demographic factors are known to impact lineup performance: country, education, and age affected score on lineup tests, and all of those factors plus gender had an effect on the amount of time spent on lineups \citep{humanfactorslineups}. In addition, lineup performance can be partially explained using statistical distance metrics \citep{distancemetriclineups}, but these metrics do not completely succeed in predicting human performance, in part due to the difficulty of representing human visual ability algorithmically.


One of the most useful features of the lineup protocol is that it allows researchers to conclusively determine which graphics show certain features more conclusively by providing an experimental protocol for comparing graphics based on the accuracy of user conclusions. In addition, lineups provide researchers with a rigorous framework for determining whether a specific graph shows a real, statistically significant effect by comparing a target plot with plots formed using permutations of the same data, providing a randomization test protocol for graphics. As a result, lineups are a useful and innovative tool for evaluating charts; on an individual level, they can also be used to evaluate a specific participant's perceptual reasoning ability in the context of statistical graphics.


\subsection{Measures of visuospatial ability}

Participants are asked to complete several cognitive tests designed to measure spatial and reasoning ability. Tasks are timed such  that participants are under  pressure to complete; participants are not expected to finish all of the problems in each section. This allows for a better discrimination between scores and prevents score compression at the top of the range. 

The \textbf{visual searching task} (VST), shown in Figure~\ref{fig:VST}, is designed to test a participant's ability to find a target stimulus in a field of distractors, thus making the visual search task similar in concept to lineups. Historically, visual search has been used as a measure of brain damage \citep{goldstein1973validity,demita1981validity,moerland1986neuropsychological}; however, similar tasks have been used to measure cognitive performance in a variety of situations, for example under the influence of drugs in~\citep{anderson1983interactive}. The similarity to the lineup protocol as well as the simplicity of the test and its' lack of color justify the slight deviation from forms of visual search tasks typically used in normal populations. 
\begin{figure}[htp]\centering
\includegraphics[width=.6\linewidth]{VisualSearch}
\caption[Visual Search Task]{Visual Search Task (VST). Participants are instructed to find the plot numbered 1-24 which matches the plot labeled ``Target". Participants will complete up to 25 of these tasks in 5 minutes.}\label{fig:VST}
\end{figure}


The \textbf{figure classification task} tests a participant's ability to extrapolate rules from provided figures. This task is associated with inductive reasoning abilities (factor I  in~\citet{ekstrom1976manual}). An example is shown in Figure~\ref{fig:figureclassification}. 

The figure classification test requires the same type of reasoning as the lineups: participants must determine the rules from the provided classes, and extrapolate from those rules to classify new figures. In lineups, participants must determine the rules based on the panels appearing in the lineup; they must then identify the plot which does not conform. As such, the figure classification test has content validity in relation to lineup performance: it is measuring similar underlying criteria. 

\begin{figure}[ht]
  \centering
  \begin{subfigure}[b]{.75\linewidth}
  \includegraphics[width=\linewidth]{figureclassification}
  \caption[Figure Classification Task]{Figure Classification Task. Participants classify each figure in the second row as belonging to one of the groups above. Participants complete up to 14 of these tasks (each consisting of 8 figures to classify) in 8 minutes.\label{fig:figureclassification}}
  \end{subfigure}
  \begin{subfigure}[b]{.75\linewidth}
  \includegraphics[width=\linewidth]{cardrotation}
  \caption[Card Rotation Task]{Card Rotation Task. Participants mark each figure on the right hand side as either the same as or different than the figure on the left hand side of the dividing line. Participants complete up to 20 of these tasks (each consisting of 8 figures) in 6 minutes.\label{fig:cardrotation}}
  \end{subfigure}
  \begin{subfigure}[b]{.75\linewidth}
  \includegraphics[width=\linewidth]{paperfolding}
  \caption[Paper Folding Task]{Paper Folding Task. Participants are instructed to pick the figure matching the sequence of steps shown on the left-hand side. Participants  complete up to 20 of these tasks in 6 minutes.\label{fig:paperfolding}}
  \end{subfigure}
  \caption[Tests of spatial ability]{Tests of spatial ability from \protect\citet{ekstrom1976manual}.}   \label{fig:tests}
\end{figure}
  
The \textbf{card rotation test} measures a participant's ability to rotate objects in two dimensions in order to distinguish between left-hand and right-hand versions of the same figure. It tests mental rotation skills, and is classified as a test of spatial orientation in~\citep{ekstrom1976manual}, though it does require that participants have both mental rotation ability and short-term visual memory. An example is shown in Figure~\ref{fig:cardrotation}. 
The card rotation test is often used in studies investigating the effect of visual ability on the use of visual aids \citep{mayer1994whom} and statistical graphs \citep{lowrie2007solving} in education.

 

% \begin{figure*}[hbt]\centering
% \includegraphics[width=.75\linewidth]{cardrotation}
% \caption[Card Rotation Task]{Card Rotation Task. Participants mark each figure on the right hand side as either the same as or different than the figure on the left hand side of the dividing line. Participants will complete up to 20 of these tasks (each consisting of 8 figures) in 6 minutes.}\label{fig:cardrotation}
% \end{figure*}
Two-dimensional comparisons are an important component of lineup performance. In some lineup situations, these comparisons sometimes involve translation, but in other lineups, rotation is required. Lineups also require visual short-term memory, so the additional factor measured implicitly by this test does not reduce its potential relevance to lineup performance.  

The \textbf{paper folding test} measures participants' ability to visualize and mentally manipulate figures in three dimensions. A sample question from the test is shown in Figure~\ref{fig:paperfolding}. It is classified as part of the visualization factor in~\citep{ekstrom1976manual}, which differs from the spatial orientation factor because it requires participants to visualize, manipulate, and transform the figure~mentally, which makes it a more complex and demanding task than simple rotation. The paper folding test is associated with the ability to extrapolate symmetry and reflection over multiple steps.
% \begin{figure*}[hbt]\centering
% \includegraphics[width=.75\linewidth]{paperfolding}
% \caption[Paper Folding Task]{Paper Folding Task. Participants are instructed to pick the figure~matching the sequence of steps shown in the left-hand figure. Participants will complete up to 20 of these tasks in 6 minutes.}\label{fig:paperfolding}
% \end{figure*}
Lineups require similar manipulations in two-dimensional space, and also require the ability to perform complex spatial manipulations mentally; for instance, comparing the interquartile range of two boxplots as well as their relative alignment to a similar set of two boxplots in another panel.

Between cognitive tasks, participants were also asked to complete three blocks of 20 lineups each, assembled from previous studies~\citep{hofmann2012graphical,majumder2013validation}. Participants have 5 minutes to complete each block of 20 lineups. Figure~\ref{fig:lineup} shows a sample lineup of box plots. 

In addition to these tests, participants were asked to complete a questionnaire which includes questions about colorblindness, mathematical background, self-perceived verbal/mathematical/artistic skills, time spent playing video games, and undergraduate major. 
These questions are designed to assess different factors which may influence a participant's skill at reading graphs and performing spatial tasks. 

\subsection{Test Scoring}\label{sec:scaling}

All test results were scored so that random guessing produces an expected value of 0; therefore each question answered correctly contributes to the score by 1, while a wrong answer is scored by $-1/(k-1)$, where $k$ is the total number of possible answers to the question. Thus, for a test consisting of multiple choice questions with $k$ suggested answers with a single correct answer each, the score is calculated as
\begin{eqnarray}\label{eq.scoring}
\# \text{correct answers } - 1/(k-1) \cdot \# \text{wrong answers}.
\end{eqnarray}
This allows us to compare each participant's score in light of how many problems were attempted as well as the number of correct responses. Combining accuracy and speed into a single number does not only make a comparison of test scores easier,  this scoring mechanism is also used on many standardized tests, such as the SAT and the battery of psychological tests~\citep{diamond1973correction, ekstrom1976manual} from which parts of this test are drawn. The advantage of using tests from the Kit of Factor Referenced Cognitive tests~\citep{ekstrom1976manual} is that the tests are extremely well studied (including an extensive meta-analysis in~\citep{voyer1995magnitude} of the spatial tests we are using in this study) and comparison data are available from the validation of these factors~\citep{schaie1998longitudinal,hampson1990variations,mayer1994whom} and previous versions of the kit~\citep{educational1963kit}.

\section{Results}\label{sec:results}
Results are based on an evaluation of \Sexpr{nrow(ans)} undergraduate students at Iowa State University. \Sexpr{round(sum(ans.summary$stem)/nrow(ans.summary)*100)}\% of the participants were in STEM fields, the others were distributed relatively evenly between agriculture, business, and the social sciences. Students were evenly distributed by gender, and were between 18 and 24 years of age with only one exception. This is reasonably representative\footnote{\url{http://www.registrar.iastate.edu/sites/default/files/uploads/stats/university/F14summary.pdf}} of the university as a whole; in the fall 2014 semester, 26\% of students were associated with the college of engineering, 24\% were associated with the college of liberal arts and sciences, 15\% were associated with the college of human sciences, 7\% with the college of design, 13\% with the business school, and 15\% with the school of agriculture.  

\subsection{Comparison of Spatial Tests with Previously Validated Results}
The card rotation, paper folding, and figure classification tests have been validated using different populations, many of which are demographically similar to Iowa State students (naval recruits, college students, late high-school students, and 9th grade students). We compare Iowa State students' unscaled scores in Table~\ref{tab:scorecomparison}, adjusting data from other populations to account for subpopulation structure and test length. 

\begin{table}[htb]
\begin{tabular}{rlllc}
\hline
  & Card Rotation & Paper Folding & Figure Classification & Visual Search  \\\hline
ISU Students & \Sexpr{round(mean(ans.summary$card_rot), 1)} (\Sexpr{round(sd(ans.summary$card_rot), 1)}) 
             & \Sexpr{round(mean(ans.summary$folding), 1)} (\Sexpr{round(sd(ans.summary$folding), 1)})
             & \Sexpr{sprintf("%.1f", mean(ans.summary$fig_class))} (\Sexpr{round(sd(ans.summary$fig_class), 1)})\footnotemark[1]
             & \Sexpr{round(mean(ans.summary$vis_search), 1)} (\Sexpr{round(sd(ans.summary$vis_search), 1)})\\
Scaled Scores & 88.0 (\Sexpr{round(sqrt((24.6^2)*2), 1)})
              & 13.8 (4.5)
              & \Sexpr{round((120.0*294 + 114.9*323)/617/2, 1)} (\Sexpr{round(sqrt((30^2*294 + 27.8^2*323)/617)/2, 1)})\footnotemark[2]
              & -- \\
Unscaled Scores & 44.0 (24.6)\footnotemark[3]
                & 13.8 (4.5)
                & \parbox[c]{.2\linewidth}{M:~120.0~(30.0)\\ F:~114.9~(27.8)}
                & --\\\hline
{\footnotesize Population}    
              & \parbox[t]{.15\linewidth}{\footnotesize approx.\ 550 male\\ naval recruits} 
              & \parbox[t]{.17\linewidth}{\footnotesize 46 college students\\(1963~version)}
              & \parbox[t]{.2\linewidth}{\footnotesize suburban 11th \& 12th \\ grade students\\(288-300 males, \\317-329 females)}
              & \\\hline
\end{tabular}
\caption[Comparison of scores for cognitive tasks.]{Comparison of scores from Iowa State students and scores reported in~\protect\citep{ekstrom1976manual}. Scaled scores are calculated based on information reported in the manual, scaled to account for differences in the number of questions answered during this experiment. Data shown are from the population most similar to ISU students, out of the data available. The visual search task~\protect\citep{goldstein1973validity,demita1981validity,moerland1986neuropsychological} is not part of the Kit of Factor Referenced Cognitive Test data, and thus we do not have comparison data for the form used in this experiment.
\label{tab:scorecomparison}}
\end{table}

Table~\ref{tab:scorecomparison} shows mean scores and standard deviation for ISU students and other populations. Values have been adjusted to accommodate for differences in test procedures and sub-population structure; for instance,  some data is reported for a single part of a two-part test, or results are reported for each gender separately. 
\footnotetext[1]{ISU students took only Part I due to time constraints.}
\footnotetext[2]{Averages calculated assuming 294 males and 323 females.}
\footnotetext[3]{Data from Part I only.}

\paragraph{Scaling Scores}\label{app:ScoreAdj}
To calculate ``scaled" comparison scores between tests which included different numbers of test sections (as shown in Table~\ref{tab:scorecomparison}), we scaled the mean in direct proportion to the number of questions (thus, if there were two sections of equivalent size, and the reference score included only one of those sections, we multiplied the reported mean score by two). The variance calculation is a bit more complicated: In the case described in the main text, where the reference section contained half of the questions, the variance is multiplied by two, causing the standard deviation to be multiplied by approximately 1.41. 

This scaling gets slightly more complicated for scores which have two sub-groups, as with the figure classification test, which separately sumarizes male and female participants' scores. 
To get a single unified score with standard deviation, we completed the following calculations: 
\begin{align}
\mu_{\text{all}} &= (N_F\mu_{F} + N_M\mu_{M})/(N_F + N_M)\\
\sigma_{\text{all}} &= \sqrt{\left(N_F\sigma_F^2 + N_M\sigma_M^2\right)/(N_F + N_M)}.
\end{align}
Here $\mu_F$ and $\mu_M$ are the mean scores for females and males, respectively; $N_F$ and $N_M$ are the number of female and male participants, and $\sigma_F^2$ and $\sigma_M^2$ are the variances in scores for females and males.

Substituting in the provided numbers, we get
\begin{align*}
\mu_{\text{all}} &= \left(323\!\cdot\!114.9\! +\! 294\!\cdot\!120.0\right)/(323\!+\!294) \\
& = \Sexpr{round((120.0*294 + 114.9*323)/617/2, 1)}\\
\sigma_{\text{all}} &= \sqrt{\left(323 \cdot 27.8^2 \!+\! 294 \cdot 30^2\right)/(323\!+\!294)} \\
& = \Sexpr{round(sqrt((30^2*294 + 27.8^2*323)/617)/2, 1)}.
\end{align*}

Whenever participants in two studies were not exposed to the same number of questions, the resulting scores are not comparable: both overall scores and their standard deviations are different. We can achieve comparability by scaling the scores accordingly.
For example, in order to account for the fact that ISU students took only part I of two parts to the figure classification test (and thus completed half of the questions), we adjust the transformation as follows:

\begin{eqnarray*}
\mu_{\text{part I}} &= 1/2 \cdot \mu_{\text{all}}\\
\sigma_{\text{part I}} &= 1/\sqrt{2} \cdot \sigma_{\text{all}}
\end{eqnarray*}


Once these adjustments have been completed, it is evident that Iowa State undergraduates scored at about the same level as other similar demographics. In fact, both means and standard deviations of ISU students' scores are similar to the comparison groups, which were chosen from available demographic groups based on population similarity. 

Comparison population data was chosen to most closely match ISU undergraduate population demographics. Thus, if comparison data was available for 9th and 12th grade students, scores of Iowa State students were compared to scores of 12th grade students, who are closer in age to college students. When data was available from college students and Army enlistees, comparisons of scores were based on other college students, as college students are more likely to have a similar gender distribution to ISU students.

Applying the grading protocol discussed in section~\ref{sec:scaling}, we see that the ranges of lineup and visuospatial test scores do not include zero; this indicates that we do not see random guessing from participants in any task. Figure~\ref{fig:Scores} shows the range of possible scores and the observed score distribution. 
Participants' scores on the VST indicate score compression; that is, both participants with medium and high visual search abilities scored at the extremely high end of the spectrum. 
In future experiments, participants should be given less time (or more questions) to better differentiate participants with medium and high-ability.
<<ResultsScaledScores, echo=F, include=F, fig.width=4.5, fig.height=4, warning=F, message=F>>=
loadfonts()
score.summary <- melt(ans.summary, measure.vars=21:25, value.name = "Score", variable.name = "Test")
score.summary$Test <- factor(score.summary$Test, levels=c("lineup", "card_rot", "fig_class", "folding", "vis_search"), labels=c("Lineups", "Card Rotation", "Figure Class.", "Paper Folding", "Visual Search"))
qrange$sqrt.k <- sqrt(qrange$k-1)
qrange$Test <- factor(qrange$testtype, levels=c("lineup", "card_rot", "fig_class", "folding", "vis_search"), labels=c("Lineups", "Card Rotation", "Figure Class.", "Paper Folding", "Visual Search"))

qr1 <- qrange
qr1$Type <- "Theoretical Range"
qr2 <- qrange
qr2$Type <- "Scores indicating guessing"
qr2$n <- with(qr2, -n/(k-1))

qrange <- rbind(qr1, qr2)
qrange$Type <- factor(qrange$Type)
qrange$Type <- factor(qrange$Type, levels=levels(qrange$Type)[2:1])

ggplot() + 
  geom_bar(data=qrange, aes(width=.9, x=Test, y=n, fill=Type), alpha=.35, stat="identity", position="identity", colour="red", inherit.aes=F) +
  scale_fill_manual("", values=c(NA, "red")) + 
  geom_boxplot(data=score.summary, aes(x=factor(Test), y=Score), inherit.aes=F, fill="grey") +
  theme_bw()  + 
  ylab("Test Scores") + 
  xlab("") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  theme(plot.margin=unit(c(0,0,0,0),"mm")) + 
  theme(legend.position=c(.68,.125),  legend.box.just = "left", 
        legend.key.height=unit(6, "mm")) 
  #coord_flip()
ggsave(paste0(imgdir, "fig-ResultsScaledScores-1.pdf"), width=4.5, height=4)
embedFonts(paste0(imgdir, "fig-ResultsScaledScores-1.pdf"))
@

\begin{figure}[ht]\centering
\includegraphics[width=.6\linewidth]{fig-ResultsScaledScores-1}
\caption[Test scores for lineups and visuospatial tests]{Test scores for lineups and visuospatial tests. As none of the participants scored at or below zero, we can conclude that there is little evidence of random guessing. We also note the score compression that occurs on the Visual Search test; this indicates that most participants scored extremely high, and thus, participants' scores are not entirely representative of their ability. \label{fig:Scores}}
\end{figure}
% 

% Applying the grading protocol discussed in section~\ref{sec:scaling}, we see that the ranges of lineup and visuospatial test scores do not include zero; this indicates that we do not see random guessing from participants in any task. Figure~\ref{fig:Scores} shows the range of possible scores and the observed score distribution. 


\subsection{Lineup Performance and Demographic Characteristics}

<<VisReasoningCategorical, echo=F, include=F, eval=T, fig.width=9,fig.height=5.5, message=F, warning=F, fig.pos='ht'>>=
loadfonts()
lineup.summary.categorical <- rbind(lineup.summary.categorical, data.frame(id=1, lineup=NA, variable="verbal_skills", value=1))
lineup.summary.categorical <- rbind(lineup.summary.categorical, data.frame(id=1, lineup=NA, variable="math_skills", value=1))
lineup.summary.categorical$variable <- factor(lineup.summary.categorical$variable, labels=c("Age", "Sex", "Math/Science Research", "Statistics Class", "Calculus 1", "Verbal Skills", "Math Skills", "Art Skills", "AutoCAD Experience", "STEM Major", "Video Game Hrs/Wk"))
lineup.summary.categorical$value[lineup.summary.categorical$value=="f"] <- "Female"
lineup.summary.categorical$value[lineup.summary.categorical$value=="m"] <- "Male"
lineup.summary.categorical$value[lineup.summary.categorical$value=="y"] <- "TRUE"
lineup.summary.categorical$value[lineup.summary.categorical$value=="n"] <- "FALSE"

tmp <- dlply(lineup.summary.categorical, .(variable), function(df){
    tmp <- anova(lm(lineup~factor(value, ordered=F), data=df))
    coefs <- as.data.frame(tmp)[1,]
    coefs$level <- gsub("factor(value, ordered = F)", unique(df$variable), rownames(coefs), fixed=T)
    rownames(coefs) <- NULL
    coefs <- coefs[,c(6, 1:5)]
    names(coefs) <- c("Variable", "DF", "Sum.of.Squares", "Mean.Squared", "F.value", "p.value")
    coefs
})

tmp <- rbind.fill(tmp)
tmp <- tmp[order(tmp$p.value, decreasing=F),]

lineup.summary.categorical$variable <- factor(lineup.summary.categorical$variable, levels=unique(tmp$Variable))
lineup.summary.categorical$value <- factor(lineup.summary.categorical$value, levels=c("0","1", "2","3","4","5","[1, 2)", "[2, 5)", "5+", "18-20", "21+", "TRUE", "FALSE", "Female", "Male"))

qplot(data=lineup.summary.categorical, x=value, y=lineup, geom="boxplot", fill=I("grey")) + 
  facet_wrap(~variable, scales="free_x", ncol=4) + xlab("") + 
  ylab("Scaled Lineup Score") + 
  geom_point(aes(x=value, y=lineup), shape=1, size=3) + 
  theme_bw() + 
  theme(plot.margin=unit(c(0,0,0,0), unit="mm"))
ggsave(paste0(imgdir, "fig-VisReasoningCategorical-1.pdf"), width=9, height=5.5)
embedFonts(paste0(imgdir, "fig-VisReasoningCategorical-1.pdf"))
@
\begin{figure*}[h!tb]\centering
\includegraphics[width=.85\linewidth]{fig-VisReasoningCategorical-1}
\caption[Visual Aptitude Study Results]{Demographic characteristics of participants compared with lineup score. Categories are ordered by effect size; majoring in a STEM field, calculus completion, hours spent playing video games per week, and sex are all associated with a significant difference in lineup score. }\label{fig:visualaptitudecat}
\end{figure*}

%Next, we examine the effect of demographic factors on lineup performance. 
Previous work found a relationship between lineup performance and demographic factors such as education level, country of origin, and age \citep{humanfactorslineups}; our participant population is very homogeneous, which allows us to explore factors such as educational background and skills on performance in lineup tests. 

Figure~\ref{fig:visualaptitudecat} shows participants' lineup scores in relationship to their responses in the questionnaire given at the beginning of the study; this allows us to explore effects of demographic characteristics (major, research experience, etc.) on test performance. 

Completion of Calculus I is associated with increased performance on lineups; this may be related to general math education level, or it may be that success in both lineups and calculus requires certain visual skills. This association is consistent with findings in~\citep{shah1995conceptual}, which associated  mathematical ability to performance on simple graph description tasks.  There is also a significant relationship between hours of video games played per week and score on lineups, however, this association is not monotonic and the groups do not have equal sample size, so the conclusion may be suspect. There is a (nearly) significant difference between male and female performance on lineups; this is not particularly surprising, as men perform better on many spatial tests~\citep{voyer1995magnitude} and performance on spatial tests is correlated with phase of the menstrual cycle in women~\citep{hausmann2000sex}. There is no significant difference in lineup performance for participants of different age, self-assessed skills in various domains, previous participation in math or science research, completion of a statistics class, or experience with AutoCAD. These demographic characteristics were chosen to account for life experience and personal skills which may have influenced the results. 

Table~\ref{tab:ttest-demographics} provides the results of a sequence of linear models fit to the lineup data. Each row in the table represents a single model, with one predictor variable (a factor with two or more levels). Due to sample size considerations, multiple testing corrections were not performed; in addition, the independent variables are correlated: in our sample, males are more likely to have completed Calculus 1, but are also more likely to spend time playing video games. As such, a model including two or more of the significant predictor variables shows all included variables to be nonsignificant. To better understand the effects of these variables, a larger study is necessary. 
<<ttests.categ, echo=F, eval=T, results='asis'>>=
tmp <- dlply(lineup.summary.categorical, .(variable), function(df){
    tmp <- anova(lm(lineup~factor(value, ordered=F), data=df))
    coefs <- as.data.frame(tmp)[1,]
    coefs$level <- gsub("factor(value, ordered = F)", unique(df$variable), rownames(coefs), fixed=T)
    rownames(coefs) <- NULL
    coefs <- coefs[,c(6, 1:5)]
    names(coefs) <- c("Variable", "DF", "Sum.of.Squares", "MeanSq", "F", "p.val")
    coefs
})

tmp <- rbind.fill(tmp)
tmp2 <- tmp[order(tmp$p.val, decreasing=F),-3]
tmp2$Variable <- gsub("Math/Science", "STEM", gsub(" Experience", "", gsub(" Hrs/Wk", " hrs", tmp2$Variable)), fixed=T)
print(xtable(tmp2, digits=c(1, 1, 0, 3, 2, 3), caption=c("Participant demographics' impact on lineup score. The table below shows each single demographic variable's association with lineup score. STEM major, completion of Calculus I, time spent playing video games, and gender all show some association with score on statistical lineups. \\label{tab:ttest-demographics}", "Participant demographics and lineup scores")), include.rownames=F, floating.environment="table", caption.placement="top")
@


\subsection{Understanding Visual Abilities and Lineup Performance}
<<correlations, echo=F, comment="|", warning=F, message=F, results='asis', size="footnotesize", include=F>>=
print(xtable(cor(ans.summary[,c("lineup","card_rot", "fig_class", "folding", "vis_search")]), digits=c(1, rep(2, 5)), caption="Correlation matrix for the five tests.\\label{tab:corrmatrix5}"), sanitize.text.function=sanitize, sanitize.rownames.function=sanitize, sanitize.colnames.function=sanitize, size="footnotesize", scalebox=.9, table.placement="htb", caption.placement="top")
@

<<VisReasoningSPM,echo=FALSE, include=F, eval=T, fig.width=8,fig.height=8, message=F, warning=F>>=
data <- ans.summary[,c("lineup", "vis_search", "fig_class", "card_rot", "folding")]
grid <- expand.grid(x=1:ncol(data), y=1:ncol(data))
grid <- subset(grid, x != y & x<y)

all <- do.call("rbind", lapply(1:nrow(grid), function(i) {
  xcol <- grid[i, "x"]
  ycol <- grid[i, "y"]

  rbind.fill(
    data.frame(
      xvar = names(data)[ycol], 
      yvar = names(data)[xcol],
      x = data[, xcol], 
      y = data[, ycol], 
      points = T,
      data
    ),
    data.frame(
      yvar = names(data)[ycol], 
      xvar = names(data)[xcol],
      x = mean(range(data[, ycol])), 
      y = mean(range(data[, xcol])),
      label = round(cor(data[,xcol], data[,ycol]), 3),
      points = F
    )
  )
}))
all$xvar <- factor(all$xvar, levels=names(data))
all$yvar <- factor(all$yvar, levels=names(data))
densities <- do.call("rbind", lapply(1:ncol(data), function(i) {
    tmp <- density(data[,i], cut = 1, adjust=.75)
    data.frame(
      xvar = names(data)[i], 
      yvar = names(data)[i],
      x = tmp$x, 
      y = tmp$y/max(tmp$y)* diff(range(tmp$x)) + min(tmp$x)
    )
  }))
fix.names <- function(values){
  values %>% 
    str_replace("lineup", "Lineups") %>% 
    str_replace("vis_search", "Visual Search") %>%
    str_replace("fig_class", "Figure Classification") %>% 
    str_replace("card_rot", "Card Rotation") %>%
    str_replace("folding", "Paper Folding")
}
loadfonts()
require(grid)
ggplot()+
  geom_point(data=subset(all, points), aes(x=x, y=y)) + 
  geom_smooth(data=subset(all, points), aes(x=x, y=y), method="lm") + 
  geom_text(data=subset(all, !points), aes(x=x, y=y, label=paste0("Correlation = \n", label))) + 
  geom_line(data=densities, aes(x=x, y=y)) + 
  facet_grid(xvar~yvar, scales="free", labeller = labeller(xvar=fix.names, yvar=fix.names)) + 
  theme_bw() + 
  theme(axis.title=element_blank(),
        plot.margin=unit(c(0,0,0,0), unit="mm"))
rm(list=c("data", "all", "densities"))
ggsave(paste0(imgdir, "fig-VisReasoningSPM-1.pdf"), width=8, height=8)
embedFonts(paste0(imgdir, "fig-VisReasoningSPM-1.pdf"))
@
\begin{figure}[ht]\centering
\includegraphics[width=.5\linewidth]{fig-VisReasoningSPM-1}
\caption[Pairwise scatterplots of test scores]{Pairwise scatterplots of test scores. Lineup scores are most highly correlated with figure classification scores, and are also highly correlated with card rotation scores. Paper folding and card rotation scores are also highly correlated.\label{fig:scatterplotmatrix}}
\end{figure}

<<pca,echo=F, warning=F, message=F>>=
pca <- prcomp(ans.summary[,c("lineup", "card_rot", "fig_class", "folding", "vis_search")], scale=T, retx=T)
pca2 <- prcomp(ans.summary[,c("card_rot", "fig_class", "folding", "vis_search")], scale=T, retx=T)
# screeplot(pca)
@

Results from the visuospatial tests used in this experiment are highly correlated, as shown in Figure~\ref{fig:scatterplotmatrix}; this is to be expected given that all of these tests are in some way measuring individuals' visual ability. 
What is of more interest to us is how other factors, such as e.g.~general intelligence, mental processing speed, cognitive resources, motivation, and attention affect performance. 
In order to assess factors contributing to lineup performance, we first examine the separate dimensions measured by the battery of cognitive tests (other than lineups) using principal components analysis on the scaled test scores, then we examine all five tests using the same procedure. 


\subsubsection{Principal Component Analysis of the Four Visuospatial Tests}

A principal component analysis (PCA) of the four established visuo-spatial tests reveals that they all share a very strong first component, which explains about \Sexpr{round(summary(pca2)$importance[3,1],2)*100}\% of the total variability. Principal components (PC-) are ordered by importance (how much variability in the data they contain), and each principal component is uncorrelated with every other principal component. 

PC1 is essentially an average across all tests representing a general ``visual intelligence" factor. The other principal components span another two dimensions, while the last dimension is weak (at \Sexpr{round(summary(pca2)$importance[2,4],2)*100}\%). 
PC2 differentiates the figure classification test from the visual searching test, whereas PC3 differentiates these two tests from the paper folding test. 

<<pcasummary4,echo=F, results='asis'>>=
pca2 <- prcomp(ans.summary[,c("card_rot", "fig_class", "folding", "vis_search")], scale=T, retx=T)
print(xtable(summary(pca2), caption=c("Importance of principal components in an analysis of four tests of spatial ability: figure classification, paper folding, card rotation, and visual search.\\label{tab:PCAvariance4}", "Spatial ability test PC importance matrix"),digits=2), sanitize.text.function=sanitize, sanitize.rownames.function=sanitize, sanitize.colnames.function=sanitize, size="footnotesize", table.placement="htb", caption.placement="top")
@
Table~\ref{tab:PCAvariance4} contains the proportion of the variance in the four cognitive tasks represented by each principal component. PC1 accounts for about \Sexpr{round(summary(pca2)$importance[3,1],1)*100}\% of the variance; Figure~\ref{fig:biplots4} and Table~\ref{tab:PCArotation4} confirm that PC1 is a measure of the similarity between all 4 tests; that is, a participant's general (or visual) aptitude. PC2 differentiates the figure classification test from the visual searching test, while PC3 differentiates these two from the paper folding test. PC4 is not particularly significant (it accounts for \Sexpr{round(summary(pca2)$importance[2,4]*100,1)}\% of the variance), but it differentiates the card rotation task from the paper folding task.

<<pcarotation4,echo=F, results='asis'>>=
print(xtable(pca2$rotation, caption=c("Rotation matrix for principal component analysis of the four cognitive tests (visual search, paper folding, card rotation, figure classification).\\label{tab:PCArotation4}", "Spatial ability tests PC rotation matrix"),digits=2), sanitize.text.function=sanitize, sanitize.rownames.function=sanitize, sanitize.colnames.function=sanitize, table.placement="htb", caption.placement="top")
@

<<biplot-pca4, fig.cap="", fig.width=4.5, fig.height=4.5, warning=F, message=F, out.width='.45\\linewidth', comment="|", fig.scap="Biplots of principal components 1-4 with observations", fig.cap="Biplots of principal components 1-4 with observations. Principal component analysis was performed on the four cognitive tests used to understand the association between the cognitive skills required for these tests and the skills required for the lineup protocol.  \\label{fig:biplots4}", echo=F, fig.env="figure">>=
par(mar=c(4,4,.1,.1),cex.lab=.95,cex.axis=.9,mgp=c(2,.7,0),tcl=-.3)
biplot(pca2, choices=1:2, pc.biplot=T, cex=c(.5, 1), xlim=c(-2.5,2.5), ylim=c(-2.5,2.5))
biplot(pca2, choices=3:4, pc.biplot=T, cex=c(.5, 1), xlim=c(-3,3), ylim=c(-2.5,2.5))
@
Figure~\ref{fig:biplots4} shows that the first PC does not differentiate between any of the tasks; it might be best understood as a general aptitude factor. All of the remaining principal components distinguish between the cognitive tasks; 
PC2 and PC3 separate  paper folding from visual search and from the lineup and figure classification tasks, while PC4 and PC5 mainly separate lineups from card rotation and figure classification. This separation allows us to compare the tasks which are similar from among the principal components. 
According to Table~\ref{tab:PCArotation4}, the first three principal components account for \Sexpr{round(summary(pca2)$importance[3,3]*100,1)}\% of the variance.

\subsubsection{Principal Component Analysis of Cognitive Tests and the Lineup Task }
Incorporating the lineup task into the principal component analysis, we find the principal components to be fairly similar to the four-component analysis. 
Table~\ref{tab:PCAvariance5} shows the importance of each principal component. From the distribution of the variance components, we see that the lineup test  spans an additional dimension within the space of the four established tests. 
<<pcasummary5,echo=F, results='asis'>>=
print(xtable(summary(pca), caption="Importance of principal components, analyzing all five tests.\\label{tab:PCAvariance5}",digits=2), sanitize.text.function=sanitize, sanitize.rownames.function=sanitize, sanitize.colnames.function=sanitize, size="footnotesize", table.placement="ht", caption.placement="top")
@

<<pcarotation5,echo=F, results='asis'>>=
print(xtable(pca$rotation, caption="PCA Rotation matrix for all five tests. 
             \\label{tab:PCArotation5}",digits=2), sanitize.text.function=sanitize, sanitize.rownames.function=sanitize, sanitize.colnames.function=sanitize, table.placement="ht", caption.placement="top")
@
From the rotation matrix (see Table~\ref{tab:PCArotation5}) we see that  
the first principal component, PC1, is again essentially an average across all tests and accounts for \Sexpr{round(summary(pca)$importance[3,1]*100,1)}\% of the variance in the data. 

<<biplots-pca5, fig.cap="", fig.width=4.5, fig.height=4.5, warning=F, message=F, out.width='.45\\linewidth', comment="|", fig.scap="Biplots of principal components 2-5 with observations.", fig.cap="Biplots of principal components 2-5 with observations. The lineup task appears to be most similar to the figure classification task, based on the plot of PC2 vs. PC3.  \\label{fig:biplots5}", echo=F, fig.env="figure">>=
par(mar=c(4,4,.1,.1),cex.lab=.95,cex.axis=.9,mgp=c(2,.7,0),tcl=-.3)
biplot(pca, choices=2:3, pc.biplot=T, cex=c(.5, 1), xlim=c(-2.5,2.5), ylim=c(-2.5,2.5))
biplot(pca, choices=4:5, pc.biplot=T, cex=c(.5, 1), xlim=c(-2,2), ylim=c(-2,2))
@

Figure classification is strongly related to lineups (PC2, PC3). Performance on the visual search task  is also related to lineup performance (PC3). These two components highlight the shared demands of the lineup task and the figure classification task: participants must establish categories from provided stimuli and then classify the stimuli accordingly. 

The visual search task is also clearly important to lineup performance: PC3 captures the similarity between the visual search and lineup performance, and aspects of these tasks are negatively correlated with aspects of the paper folding and card rotation tasks within PC3. Paper folding does not seem to be strongly associated with lineup performance outside of the first principal component; card rotation is only positively associated with lineup performance in PC4.

PC4 captures the similarity between lineups and the card rotation task and separates this similarity from the figure classification task; this similarity does not account for much extra variance (10\%), but it may be that only some lineups require spatial rotation skills. PC5 contains only 5\% of the remaining variance, and is thus not of much interest, however, it seems to capture the relationship between the card rotation task and the paper folding and visual search tasks.


Figure classification is strongly related to lineups, and as in the four-component PCA, figure classification is strongly represented in the first two principal components. While lineups do span a separate dimension, the PCA suggests that they are most closely related to the figure classification task, and least related to the visual searching task.

% 
% The additional dimension, PC4 in the five-component PCA, separates lineups from the figure classification task and incorporates the relatively weak correlation between performance on the card rotation task and lineup performance; this dimension accounts for \Sexpr{round(summary(pca)$importance[2,4]*100,1)}\% of the variance. 
% PC5 is almost identical to PC4 in the four-component PCA; as before, it does not account for a significant portion of the variance in the data.
% 

This emphasizes the underpinnings of lineups: the test utilizes a visual medium, but is ultimately are a classification task presented in a graphical manner. Using lineups as a proxy for statistical significance tests is similar to using a classifier on pictoral data: while the data is presented ``graphically", the participant is actually classifying the data based on underlying summary statistics.


\subsection{Linear model of demographic factors}
Note that all of the demographic variables in the survey are highy correlated, for example there is a high correlation between STEM majors and taking calculus.
Similarly, the correlation  between having taken a statistics class and having been involved in mathematics or statistics research is high. Only one student is doing research who has not taken a statistics course. 

A principal component of the five math/stats questions splits the variables into two main areas: the first principal component is an average of math skills, calculus 1 and STEM, while the second principal component is an average of having taken a statistics class and doing research. We therefore decided to use sums of these variables to come up with a separate math and a stats score. Note, that the correlation between the math and the stats score is almost zero. 
<<linearmodel, results='hide', echo=FALSE>>=
pca2 <- prcomp(ans.summary[,c("card_rot", "fig_class", "folding", "vis_search")], scale=T, retx=T)
ans.model <- data.frame(ans.summary, data.frame(pca2$x))
# exclude all variables that are not supposed to go into the linear model
# those are the unrotated tests; instead we have the PCs
excl <- c("id", "card_rot", "fig_class", "folding", "vis_search", "vidgame_hrs", "major1", "major2", "minor1", "minor2", "learning_disability", "colorblind", "epilepsy", "normal_vision")

ans.model$math_science_research <- ans.model$math_science_research=="y"
ans.model$stats_class <- ans.model$stats_class=="y"
ans.model$calc_1 <- ans.model$calc_1=="y"
pcmath <- prcomp(ans.model[,c("math_science_research", "stats_class", "calc_1", "math_skills", "stem")], scale=T)
pcmath$rotation
# first component of math PCA is average of math_skills, calc_1 and stem
# second component is stat_class and research

#biplot(pcmath)
#biplot(pcmath, 3:4)


xtabs(~stem+sex, data=ans.model)
# sad day! 

xtabs(~stem+calc_1, data=ans.model)
# stem major is more associated with performance on lineups than calc 1...

xtabs(~stats_class+math_science_research, data=ans.model)
# only one kid is doing research without a stats class

# recode to sum of them
ans.model$STATS <- with(ans.model, stats_class + math_science_research)
ans.model$MATH <- with(ans.model, calc_1+math_skills/5+stem)

excl <- c(excl, c("math_science_research", "stats_class"))
excl <- c(excl, c("calc_1", "math_skills", "stem"))
incl <- setdiff(names(ans.model), excl)

m0 <- lm(lineup~., data=ans.model[, incl])

# use AIC in backward selection
library(MASS)
m1 <- stepAIC(m0, direction="both")
@
We fit a linear model of lineup scores in the thus modified demographic variables and the test scores from the visuo-spatial tests, selecting the best model using AIC and stepwise backwards selection. The result is shown in Table~\ref{tab:m1}. Only two covariates stay in the model: PC1 and MATH, reflecting two dimensions of what affects lineup scores. We can think of PC1 as a measure of innate visual or intellectual ability, while the MATH score is a matter of both ability and training. The remaining principal components were not sufficiently associated with lineup score to be included in the model.

<<modelresults, echo=FALSE, results='asis'>>=
library(xtable)
print(xtable(summary(m1), caption="Estimates for a linear model of lineup scores.", label="tab:m1"), caption.placement="top")
@
\subsection{Lineup Types}
Each of the three sets of 20 lineups was taken from previous studies on different designs to investigate which plot type most effectively conveyed important characteristics of the underlying data set. 

\subsubsection{Example Lineups}
\subsection{Lineup Set 1}
The experiment in the first lineup section examined the use of boxplots, density plots, histograms, and dotplots to compare two groups which vary in mean and sample size. The experiment was originally designed to explore the use of lineups to test plots of competing design\citep{hofmann2012graphical}. This set of lineups consists of 20 plots selected from the plots used in the full experiment; each set of data is displayed with each of the four plot types. 
\begin{figure}[htbp]\centering
\begin{subfigure}[b]{.49\linewidth}
\includegraphics[keepaspectratio=T,width=\linewidth]{Lineups1/boxplot_1_15_5_4_13}
\caption{Boxplot}
\end{subfigure}
\begin{subfigure}[b]{.49\linewidth}
\includegraphics[keepaspectratio=T,width=\linewidth]{Lineups1/density_1_15_5_4_13}
\caption{Density plot}
\end{subfigure}
\begin{subfigure}[b]{.49\linewidth}
\includegraphics[keepaspectratio=T,width=\linewidth]{Lineups1/dotplot_1_15_5_4_13}
\caption{Dotplot}
\end{subfigure}
\begin{subfigure}[b]{.49\linewidth}
\includegraphics[keepaspectratio=T,width=\linewidth]{Lineups1/histogram_1_15_5_4_13}
\caption{Histogram}
\end{subfigure}
\caption[Lineup Set 1 Examples]{Types of plots in the first set of lineups. These plots are used to compare two distributions. }
\end{figure}
\subsection{Lineup Set 2}
The second lineup section also explored two groups of data, this time comparing boxplots, bee swarm boxplots, boxplots with overlaid jittered data, and violin plots. Participants were much more accurate in this experiment than in the experiment described previously, because of the types of plots compared as well as the underlying data distributions. 
\begin{figure}[htbp]\centering
\begin{subfigure}[b]{.49\linewidth}
\includegraphics[keepaspectratio=T,width=.45\linewidth]{Lineups2/file147f94f6965d7}
\caption{Boxplots.}
\end{subfigure}
\begin{subfigure}[b]{.49\linewidth}
\includegraphics[keepaspectratio=T,width=.45\linewidth]{Lineups2/file147f9e65f0e4}
\caption{Boxplots with jittered points.}
\end{subfigure}
\begin{subfigure}[b]{.49\linewidth}
\includegraphics[keepaspectratio=T,width=.45\linewidth]{Lineups2/file147f9fc58d73}
\caption{Bee swarm boxplots.}
\end{subfigure}
\begin{subfigure}[b]{.49\linewidth}
\includegraphics[keepaspectratio=T,width=.45\linewidth]{Lineups2/file147f93acbb7e4}
\caption{Violin plots.}
\end{subfigure}
\caption[Lineup Set 2 Examples]{Types of plots in the second set of lineups. These plots are used to compare two distributions. }
\end{figure}
\subsection{Lineup Set 3}
The final lineup section explored QQ-plots from various model simulations, using reference lines, acceptance bands, and rotation to determine which plots allowed participants to most effectively identify violations of normality. Rotated QQ-plots showed lower performance because participants were able to more accurately compare acceptance bands to residuals, and thus could identify that the reference bands were too liberal. As a result, performance was somewhat lower for rotated plots, even though participants were more accurate when comparing the residuals to the reference bands.
\begin{figure}[htbp]\centering
\begin{subfigure}[b]{.49\linewidth}
\includegraphics[keepaspectratio=T,width=.45\linewidth]{Lineups3/file13876a225d34-single}
\caption{QQ-plot with guide line.}
\end{subfigure}
\begin{subfigure}[b]{.49\linewidth}
\includegraphics[keepaspectratio=T,width=.45\linewidth]{Lineups3/file13877c93dc78-single}
\caption{QQ-plot with acceptance bands.}
\end{subfigure}
\begin{subfigure}[b]{.49\linewidth}
\includegraphics[keepaspectratio=T,width=.45\linewidth]{Lineups3/file13878e5c92f-single}
\caption{QQ-plot rotated 45 degrees.}
\end{subfigure}
\caption[Lineup Set 3 Examples]{Types of plots in the third set of lineups. These plots are used to assess residual normality. }
\end{figure}

\subsubsection{Cognitive Test Scores and Lineup Performance by Lineup Task}

<<LineupTypeSPM,echo=FALSE,include=F, eval=T, fig.width=4,fig.height=6.5, message=F, warning=F>>=
data <- lineup.section.summary[,c("lineup_1", "lineup_2", "lineup_3", "vis_search", "fig_class", "card_rot", "folding")]
grid <- expand.grid(x=1:ncol(data), y=1:ncol(data))
grid <- subset(grid, x != y & x<y)

all <- do.call("rbind", lapply(1:nrow(grid), function(i) {
  xcol <- grid[i, "x"]
  ycol <- grid[i, "y"]

  rbind.fill(
    data.frame(
      xvar = names(data)[ycol], 
      yvar = names(data)[xcol],
      x = data[, xcol], 
      y = data[, ycol], 
      points = T,
      data
    ),
    data.frame(
      yvar = names(data)[ycol], 
      xvar = names(data)[xcol],
      x = mean(range(data[, ycol])), 
      y = mean(range(data[, xcol])),
      label = round(cor(data[,xcol], data[,ycol]), 3),
      points = F
    )
  )
}))
all$xvar <- factor(all$xvar, levels=names(data))
all$yvar <- factor(all$yvar, levels=names(data))
densities <- do.call("rbind", lapply(1:ncol(data), function(i) {
    tmp <- density(data[,i], cut = 1, adjust=.75)
    data.frame(
      xvar = names(data)[i], 
      yvar = names(data)[i],
      x = tmp$x, 
      y = tmp$y/max(tmp$y)* diff(range(tmp$x)) + min(tmp$x)
    )
  }))
fix.names <- function(values){
  values %>% 
    str_replace("lineup", "Lineups") %>% 
    str_replace("Lineups_", "Lineup ") %>%
    str_replace("vis_search", "Visual Search") %>%
    str_replace("fig_class", "Figure Class.") %>% 
    str_replace("card_rot", "Card Rotation") %>%
    str_replace("folding", "Paper Folding")
}

all2 <- subset(all, grepl("lineup", yvar) & points & !grepl("vis_search", xvar))
# names(all2)[1:4] <- c("yvar", "xvar", "y", "x")
all2mean <- rbind(
  ddply(subset(all2, !grepl("lineup", xvar)), .(xvar, yvar), summarize, label=paste0("rho == ", round(cor(x,y), 3)), x=min(x)-diff(range(x))/5, y=max(y)+diff(range(y))/5, hjust=0, vjust=1, size=3),
  ddply(subset(all2, grepl("lineup", xvar) & grepl("lineup", yvar)), .(xvar, yvar), function(df){
    with(df, data.frame(xvar=unique(yvar), yvar=unique(xvar), 
                        x=mean(range(y)), y=mean(range(x)), 
                        label=paste0("rho == ", round(cor(x,y),3)),
                        hjust=.5, vjust=.5, size=4))
    })
)
loadfonts()
ggplot()+
  geom_point(data=subset(all2, points), aes(x=x, y=y)) + 
  geom_smooth(data=subset(all2, points), aes(x=x, y=y), method="lm") + 
  geom_text(data=all2mean, aes(x=x, y=y, label=label, hjust=hjust, vjust=vjust, size=size), parse=T) + 
  scale_size_identity() + 
  geom_line(data=subset(densities, grepl("lineup", xvar)), aes(x=x, y=y)) + 
  facet_grid(xvar~yvar, scales="free", labeller = labeller(xvar=fix.names, yvar=fix.names)) + 
  theme_bw() + 
  theme(axis.title=element_blank())
ggsave(paste0(imgdir, "fig-LineupTypeSPM-1.pdf"), width=4, height=6.5, units="in")
embedFonts(paste0(imgdir, "fig-LineupTypeSPM-1.pdf"))
@


\begin{figure}[ht]\centering
\includegraphics[width=.5\linewidth]{fig-LineupTypeSPM-1}
\caption[Pairwise scatterplots of test scores and lineups separated by task]{Pairwise scatterplots of test scores, with lineups separated into the three lineup tasks. All lineup tasks are moderately correlated with the figure classification task, and while tasks 1 and 2 are most strongly correlated with figure classification, lineup task 3 is most strongly correlated with the card rotation and paper folding tasks. \label{fig:lineuptaskmatrix}}
\end{figure}
Figure~\ref{fig:lineuptaskmatrix} shows the correlations between the three lineup tasks and the figure classification, card rotation, and paper folding tasks. The visual search task is only slightly correlated with the three lineup tasks and is therefore omitted from this figure. Performance on lineup tasks 1 and 2, which dealt with the distributuion of two groups of numerical data, is most strongly correlated with the performance on the figure classification task, which measures general reasoning ability.
Performance on lineup task 3, which investigated the potential to visually identify nonnormality in residual QQ-plots, is more associated with the card rotation and paper folding tests, which measure visuospatial ability. This suggests that certain lineup tasks may require more visual ability than others; in the case of the QQ-lineups a successful evaluation  needed  participants to mentally rotate plots to compare vertical distances, requiring more mental manipulation than the first two lineup tasks.


In order to examine which lineup tasks are most closely associated with visual abilities tested in the aptitude portions of an experiment, we employ principal component analysis on participant scores averaged across each block of lineups.

Principal component analysis separates multivariate data into orthogonal components using a rotation matrix to transform correlated input data into an orthogonal space. The importance of a principal component is also evaluated to assess the proportion of the overall variance in the data contained within the component (Table \ref{tab:PCAvariance5} shows the importance of each PC for the analysis of the aggregate lineup score and the four aptitude tests). 
<<lineupblockpca, echo=F, include=F, warning=F, message=F, fig.width=6, fig.height=4>>=
lineup.block.pca <- prcomp(lineup.section.summary[,c("lineup_1", "lineup_2", "lineup_3", "card_rot", "fig_class", "folding", "vis_search")], scale=T, retx=T)
rotation <- melt(lineup.block.pca$rotation)
importance <- as.data.frame(summary(lineup.block.pca)$importance)[2,]
rotation <- merge(rotation, melt(importance, variable.name="Var2", value.name="importance"))
rotation$Var1 <- factor(rotation$Var1, 
                        levels=c("vis_search", "folding", "card_rot", "fig_class", "lineup_3", "lineup_2", "lineup_1"),
                        labels=c("Visual Search", "Paper Folding", "Card Rotation", "Figure Class.", "Lineup Test 3", "Lineup Test 2", "Lineup Test 1"))
library(grid) # needed for arrow function
loadfonts()
qplot(x=0,  y=Var1, xend=value*importance, yend=Var1, geom="segment", data=rotation, arrow=arrow(length=unit(0.1, "cm"))) + facet_wrap(~Var2, ncol=4) + xlab("Influence") + ggtitle("Lineup Types and Visual Aptitude") + ylab("") + theme_bw() 
ggsave(paste0(imgdir, "fig-lineupblockpca-1.pdf"), width=6, height=4)
embedFonts(paste0(imgdir, "fig-lineupblockpca-1.pdf"))
@

\begin{figure}[ht]\centering
\includegraphics[width=.5\linewidth]{fig-lineupblockpca-1}
\caption[Principal component influence]{Principal Component influence plot, showing each input variable's contribution to the principal component, scaled by the proportion of variability in the data contained in the principal component.\label{fig:influence}}
\end{figure}

For variables $X_i$, $i=1, ..., K$ a principal component analysis results in a set of $K$ principal  components $PC_j$, $j=1, ..., K$, given as the rows of the rotation matrix, $M$ (which has dimension $K\times K$, indexed by $i$ and $j$ respectively).

The importance $I_j$ of each component is determined by the amount of variability the data exhibits along each of the principal axis.

The influence of variable $X_i$ on component $PC_j$ is then defined as:
%
$$\text{Influence of variable} X_i \text{ on PC}_j = M_{ij}\times I_j$$
%
Influence is therefore a measure of the contribution of an input variable to the principal component, scaled by the importance of that principal component to the overall variability in the data. Small (absolute) values indicate that there is little influence of $X_i$ on $PC_j$; negative values show the direction of the influence (to maintain the separation of variables as part of principal components analysis). 

Figure~\ref{fig:influence} shows the influence of each input variable on each principal component for a principal component analysis  including each lineup task as a separate input variable. The input variables are shown on the $y$ axis, with the influence of the variable on each PC shown on the $x$ axis. This allows us to consider the rotation matrix visually (while accounting for the importance of each principal component); for instance, we see that again, the first PC accounts for most of the variance and seems to represent general visual aptitude. 

PC2 emphasizes the overlapping variation in performance on lineup test 1 and the figure classification test. PC3 emphasizes the additional variation in performance on lineup test 3 and the visual search test, while PC4 emphasizes the extra variability in performance on lineup test 2 and the paper folding test. All three lineups, plus the figure classification, paper folding, and visual search tests contribute to PC5. PC6 and PC7 jointly account for less than 10\% of the variance in the data and do not display any distinct patterns in the loadings. 

While lineups constitute a distinct principal component when aggregated into a single score, this PCA of the separate lineup types and the cognitive tests indicates that different lineup experiments exist in different principal component loadings. Overall, there is an additional principal component gained from separating the lineup blocks by experiment type. As lineup tasks 1 and 2 contained similar plot types, it is possible that those two tasks overlap in the component space while lineup task 3 is distinct. 

<<removeAptitude,echo=F,fig.width=8, fig.height=4>>=
vistests <- scale(lineup.section.summary[,c("card_rot", "fig_class", "folding", "vis_search")])
lineups <- scale(lineup.section.summary[,c("lineup_1", "lineup_2", "lineup_3")])
vmain <- rowSums(vistests)/4
alltests <- data.frame(vmain, vistests-vmain, lineups)
pctests <- prcomp(alltests)
par(mfrow=c(1,2), mar=c(4,4.5,.1,.1), tcl=-0.01, cex.lab=.8,cex.axis=.7,mgp=c(2,.7,0),tcl=-.3)
#biplot(pctests)
#biplot(pctests, 3:4)
@


The relationship between participant performance on different types of lineups (and different types of plots) and performance on tests of spatial ability bears further investigation; this study suggests that there may be an effect, but there is simply not enough variation to make definitive conclusions about the relationship between different measures of visual aptitude and performance on specific lineup tasks. 

A larger study might not only address the question of which lineup tasks require certain visual skills, but also the use of different types of plots from a perceptual perspective. Preliminary results of performance on different types of plots are shown below, but a larger study is needed for definitive results. The advantage of the lineup protocol is that it allows us to not only consider individual performance but also to compare aggregate performance on different types of plots. Integrating information about the visual skills required for each type of plot provides information about the underlying perceptual skills and experience required to read different types of plots.

\subsection{Lineup Plot Types} \label{app:plottypes}
We can also compare participants' performance on specific types of lineup plots compared with their scores on the visual aptitude tests, for instance, accuracy on lineups which require mental rotation may be related to performance on the card rotation task. 

<<lineup-types,echo=F, fig.width=4, fig.height=8, include=F, warning=F, message=F>>=
lineup.type.sum2$plot.type <- str_replace(lineup.type.sum2$plot.type, "rotated", "rot")
lineup.type.sum2$plot.type <- str_replace(as.character(lineup.type.sum2$plot.type), "error", "err")
lineup.type.sum2$plot.type <- factor(lineup.type.sum2$plot.type, 
                                     levels=c("violinplot", "jitter.boxplot", "bee.swarm.boxplot", "boxplot", 
                                              "scatterplot", "density", "histogram", 
                                              "qq.line", "qq.line.err", "qq.line.err.rot"), 
                                     labels=c("Violin Plot", "Boxplot + Points", "Bee Swarm Boxplot", "Boxplot", 
                                              "Scatterplot", "Density Plot", "Overlaid Histogram", 
                                              "QQ-plot + Line", "QQ-plot +\nAcceptance Band", 
                                              "Rotated QQ-plot +\nAcceptance Band")
                                     )
loadfonts()
qplot(data=subset(lineup.type.sum2, !is.na(plot.type)& testtype=="lineup"), 
      x=score, y=..scaled.., colour=factor(testnum), geom="density", cut=4) + 
  facet_wrap(~plot.type, ncol=2) + 
  xlab("Proportion of Lineups Correct") + 
  ylab("Density") + 
  geom_vline(aes(xintercept=0), linetype=3) + 
  scale_colour_discrete("Lineup Test Number") + 
  scale_x_continuous(breaks=c(-.33, 0, .33, .67, 1)) +
  scale_y_continuous(breaks=c(0, .5, 1)) +
  theme_bw() + 
  theme(legend.position="bottom", legend.direction="horizontal", 
        axis.text.x=element_text(angle=30, hjust=1),
        plot.margin=unit(c(0,0,0,0),"mm"), 
        axis.ticks.y=element_blank(), axis.text.y=element_blank())
ggsave(paste0(imgdir, "fig-lineup-types-1.pdf"), width=4, height=8)
embedFonts(paste0(imgdir, "fig-lineup-types-1.pdf"))
@

\begin{figure}[ht]\centering
\includegraphics[width=.45\linewidth]{fig-lineup-types-1}
\caption[Density plots of scaled scores for different types of lineups]{Density plots of scaled scores for different types of lineups. For the same experiment (shown by line color), certain types of plots are more difficult to read and are associated with lower participant scores. \label{fig:plottypesdensity}}
\end{figure}

Figure~\ref{fig:plottypesdensity} compares performance on each different type of plot. The $x$ axis shows scaled score, the $y$ axis shows the density of participant scores. As two different lineup tasks utilized boxplots to test different qualities of the distribution of data (outliers vs. difference in medians), different tasks are shown as different colors, so that accuracy on tasks which are shown in blue can be compared to other blue density curves. 

Figure~\ref{fig:scatterplottypes} shows the association between scaled score on each type of lineup and score on the visual reasoning tests. Sample size for each plot type is fairly small - between 5 and 10 plots per individual, so there is low power for systematic inference, but we can establish that the card rotation task is much more significantly associated with the QQ-plots tasks compared to the other tasks. In addition, rotated QQ-plots seem to be much more asssociated with the paper folding task scores than other QQ-plot tasks; this may be because they require more visual manipulation than other QQ-plots.


<<lineup-types-scores,echo=F,fig.width=6, fig.height=12, include=F, warning=F, message=F>>=
lineup.type.sum3 <- dcast(lineup.type.sum2, id + testtype ~ plot.type, value.var="score", fun.aggregate = mean)
other.scores <- subset(lineup.type.sum3, testtype!="lineup")[,c(1,2,13)]
names(other.scores)[3] <- "testscore"
lineup.scores <- melt(subset(lineup.type.sum3, testtype=="lineup")[,c(1,3:12)], id.vars = 1)
names(lineup.scores)[2:3] <- c("lineup.type", "lineup.pct")
lineup.type.sum3 <- merge(other.scores, lineup.scores, all.x=T, all.y=T)
lineup.type.sum3$lineup.type <- factor(lineup.type.sum3$lineup.type, 
                                     levels=c("Violin Plot", "Boxplot + Points", "Bee Swarm Boxplot", "Boxplot", 
                                              "Scatterplot", "Density Plot", "Overlaid Histogram", 
                                              "QQ-plot + Line", "QQ-plot +\nAcceptance Band", 
                                              "Rotated QQ-plot +\nAcceptance Band"), 
                                     labels=c("Violin Plot", "Boxplot\n + Points", "Bee Swarm \nBoxplot", "Boxplot", 
                                              "Scatter\nPlot", "Density\nPlot", "Overlaid\nHistogram", 
                                              "QQ-plot\n+ Line", "QQ-plot\n+ Bands", 
                                              "Rotated QQ\nplot + Bands")
                                     )

cor.labels <- ddply(lineup.type.sum3, .(lineup.type, testtype), summarize, x=min(testscore), y=max(lineup.pct), label=paste0("cor = ", round(cor(testscore, lineup.pct), 2)))
loadfonts()
qplot(data=subset(lineup.type.sum3, testtype!="vis_search"), 
      x=testscore, y=lineup.pct, geom=c("smooth", "jitter"), colour=I("grey30"), method="lm") + 
  facet_grid(lineup.type~testtype, scales="free_x") + 
  ylab("Scaled Lineup Score") + 
  xlab("Test Score")+
  geom_text(data=subset(cor.labels, testtype!="vis_search"), aes(x=x, y=1, label=label), hjust=0, vjust=1, size=3) + 
  theme_bw() + 
  theme(legend.position="bottom", legend.direction="horizontal", 
        axis.text.x=element_text(angle=30, hjust=1),
        plot.margin=unit(c(0,0,0,0),"mm"))
ggsave(paste0(imgdir, "fig-lineup-types-scores-1.pdf"), width=6, height=12)
embedFonts(paste0(imgdir, "fig-lineup-types-scores-1.pdf"))
@
\begin{figure}[ht]\centering
\includegraphics[width=.5\linewidth]{fig-lineup-types-scores-1}
\caption[Scatterplots of scaled lineup scores by aptitude test scores]{Scatterplots of scaled lineup scores by aptitude test scores. There is some indication that different types of lineup tasks may utilize different visual skills; for instance, QQ-plots with confidence bands may require more skill at mental rotation than QQ-plots without the bands. \label{fig:scatterplottypes}}
\end{figure}

For comparison, the correlation between general lineup score (non-subdivided) and the card rotation test score was \Sexpr{sprintf("%.3f", cor(ans.summary$lineup, ans.summary$card_rot))}, the correlation between general lineup score and the figure classification test was \Sexpr{sprintf("%.3f", cor(ans.summary$lineup, ans.summary$fig_class))}, and the correlation between lineup score and the paper folding test was \Sexpr{sprintf("%.3f", cor(ans.summary$lineup, ans.summary$folding))}.While we can compare the correlation strength between tasks, it is clear that the correlation between the score on any single lineup type and a particular visual aptitude score is lower than the overall relationship that we attribute to visual ability. Additional data is imperative to understand the reasoning required for specific types of plots - it is likely that the 5-10 trials per participant presented in each chart in Figure~\ref{fig:scatterplottypes} are simply not sufficient to uncover any specific relationship between reasoning ability and lineup task. 



\section{Discussion and Conclusions}\label{sec:discussion}

Performance on lineups is strongly related to performance on tests of visual ability; however, this relationship is mediated by demographic factors such as major (STEM or not) and completion of calculus I.
In addition to these demographic factors, many facets of intelligence are highly correlated; participants who score higher on general aptitude tests may score higher on tests of visual ability (and may also score higher on lineup tests).

Despite these caveats, we have demonstrated that the general lineup task is most closely related to a classification task, rather than tests of spatial ability.
This is an important verification of a tool that is useful for examining statistical graphics, as it emphasizes the idea that while the testing medium is graphical in nature, the task is in fact a classification task, where the viewer must determine the most important features of each plot and then identify which plot is different.

When lineup tasks with different goals are viewed separately, there is some indication that different tasks are associated with different visual abilities.
Lineup tasks 1 and 2 are quite similar, and are more associated with the figure classification task; lineup task 3, while still moderately correlated with the figure classification task, is also moderately correlated with the visuospatial ability tests (paper folding, card rotation).
Future studies testing larger sets of lineups may be useful to understand which types of plots require additional visuospatial skills, as plots which appeal to a wider audience may be more successful when conveying important information.

In addition to this theoretical information, the figure classification test may be useful for pre-screening participants in future online lineup studies.
Such studies often suffer from participants who do not take the task seriously, and internal verification questions, as well as pre-qualification tasks are often used to reduce extraneous variability.
While it is impractical to require participants to score well on several different tests, it is reasonable to ask participants to pre-qualify for a task by completing a figure classification test.
As the figure classification test is different from the lineup task, this will not bias participants' scores on the domain of interest while ensuring that the participant pool is sufficiently motivated to complete the lineup questions.

The demographic results from this study indicate that in future lineup studies, it may be important to record information about participants' mathematical training, so that studies can be compared across participant pools with more reliability. 

All results and data shown here were collected and analyzed in accordance with IRB \# 13-581.
